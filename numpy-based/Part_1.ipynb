{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## Tabular Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A gridworld environment\n",
    "\n",
    "In order to build some intuition about RL methods, we are going to begin with a value function approximator method: Q-learning. To keep things simple we are going to implement Q-learning in its tabular form (i.e. without any function approximation).\n",
    "\n",
    "The first environment we are going to study is a discrete-space grid-world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by importing the required python modules: numpy, matplotlib and the gridworld environment.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from envs.environments import cliff_walking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an instance of the environment and we render it to see what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAACPCAYAAADTJpFmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAAlRJREFUeJzt2rFtwlAUQFEbwUTMkJ6GIdiCfTIBYolMkSY78FkAkCgcX4lzShfPr7p6xZ/HGBMAXZu1FwDgNaEGiBNqgDihBogTaoA4oQaI2y4x9Gtz9OYP4E3X2/f86LuLGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIG67xNDL788SY5/an0//+j/gM+wOf2uvME2TixogT6gB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIG4eY6y9AwAvuKgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHihBogTqgB4oQaIE6oAeKEGiBOqAHi7k9tD+YE65nsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of the environment\n",
    "env = cliff_walking()\n",
    "env.reset()\n",
    "# Lets render the enviroment to see what we are dealing with\n",
    "env_map = env.render()\n",
    "plt.figure()\n",
    "plt.imshow(env_map,cmap='viridis');\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent (yellow) is going to be trained to achieve the goal cell (green). The obstacles (blue) are places where the agent cannot move to. The agent is inialized randomly in any of the empty cells (dark-purple).\n",
    "\n",
    "The agent can execute 4 actions: 0-UP, 1-RIGHT, 2-DOWN, 3-LEFT. Each action drives the agent one cell in the corresponding direction. If the agent attemps to move towards an obstacle or the limit of the gridworld, it will remain at its current position.\n",
    "\n",
    "The environment provides the agent with the following reward:\n",
    "* R = 1.0 if the agent achieves the goal.\n",
    "* R = 0.0 otherwhise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid_world_v1(cliff_walking):\n",
    "    def reward(self):\n",
    "        agent, target = self.observe()\n",
    "        if agent==target:\n",
    "            return 0.0\n",
    "        elif agent in self._cliff:\n",
    "            return -100.0\n",
    "        else:\n",
    "            return -1.0\n",
    "    \n",
    "class grid_world_v1(cliff_walking):\n",
    "    def reward(self):\n",
    "        agent, target = self.observe()\n",
    "        if agent==target:\n",
    "            return 0.0\n",
    "        elif agent in self._cliff:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return -0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to train the agent?\n",
    "As mentioned before we are going to approximate the value function of the agent following a greedy policy (executing always the action that provides more value).\n",
    "\n",
    "So we are going to learn the mapping: $S\\times A\\rightarrow \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.Qlearning import tabular_Qlearning\n",
    "from utilities import plot_policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class our_Qlearning(tabular_Qlearning):\n",
    "    def train(self,state,action,next_state,reward,done):\n",
    "        if (not done):\n",
    "            BE = reward + self._gamma*np.amax(self.Qtable[next_state,:]) - self.Qtable[state,action]\n",
    "        else:\n",
    "            BE = reward - self.Qtable[state,action]\n",
    "        self.Qtable[state,action] += self._alpha*BE\n",
    "        return 0.5*np.square(BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "UP, RIGHT, DOWN, LEFT\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ0AAAA/CAYAAAD68sozAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAAPFJREFUeJzt3DERAjEQQNHcDXhABi0C6GmwgDqE4AEJ4OFQcO1PwXttit3iT5rMZNm2bUBpnb0A/0d05ERHTnTkREdOdORER0505ERHTnTkDrMX2HNd7+n73PdxKceN4+2Tznudn+m89fReds/KRWAM0TGB6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MgtvvSn5qYjJzpyoiMnOnKiIyc6cqIjJzpyoiMnOnKiIyc6cqIjJzpyoiMnOnKiIyc6cqIjJzpyoiMnOnKiI/cDFxgNeftd74AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAB/CAYAAAByvn5wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAAdhJREFUeJzt2rERAjEMAEH8Q2uU8FVSAr0hGiD9d3C7oQKPohsFXjPzACg4di8AcBfBAzIED8gQPCBD8IAMwQMynlc8+jpOf12AbT7f9/o3d+EBGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QsWZm9w4At3DhARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekCF4QIbgARmCB2QIHpAheECG4AEZggdkCB6QIXhAhuABGYIHZAgekPEDcu8K+cyR7v0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_states = env.num_states\n",
    "n_actions = env.num_actions\n",
    "agent = our_Qlearning(n_states,n_actions,lr=0.1)\n",
    "policy = [agent.get_policy()]\n",
    "plot_policies(env,policy,size=(30,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(env,agent,max_episodes,max_steps,start='standar'):\n",
    "    np.random.seed(1234) # Fixed random seed\n",
    "    policies = []\n",
    "    for episode in range(max_episodes+1):\n",
    "        state = env.reset(start)\n",
    "        done = False\n",
    "        step = 1\n",
    "        policies.append(agent.get_policy())\n",
    "        while (not done and step <= max_steps):\n",
    "            action = agent.epsilon_greedy(state)\n",
    "            next_state,reward,done = env.step(action)\n",
    "            agent.train(state,action,next_state,reward,done)\n",
    "            state = next_state\n",
    "            step += 1\n",
    "        agent.epsilon_decay(rate=0.995,min=0.01)\n",
    "        agent.alpha_decay(rate=0.999,min=0.01)\n",
    "        if(episode%(max_episodes/10)==0):\n",
    "            print('Episode: ',episode,' Steps: ',step,\n",
    "                  ' Exploration: ',np.round(agent._epsilon,2),' L.R: ',np.round(agent._alpha,2))\n",
    "    return policies\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0  Steps:  18  Exploration:  1.0  L.R:  0.1\n",
      "Episode:  100  Steps:  20  Exploration:  0.6  L.R:  0.09\n",
      "Episode:  200  Steps:  38  Exploration:  0.37  L.R:  0.08\n",
      "Episode:  300  Steps:  19  Exploration:  0.22  L.R:  0.07\n",
      "Episode:  400  Steps:  33  Exploration:  0.13  L.R:  0.07\n",
      "Episode:  500  Steps:  25  Exploration:  0.08  L.R:  0.06\n",
      "Episode:  600  Steps:  33  Exploration:  0.05  L.R:  0.05\n",
      "Episode:  700  Steps:  16  Exploration:  0.03  L.R:  0.05\n",
      "Episode:  800  Steps:  14  Exploration:  0.02  L.R:  0.04\n",
      "Episode:  900  Steps:  14  Exploration:  0.01  L.R:  0.04\n",
      "Episode:  1000  Steps:  14  Exploration:  0.01  L.R:  0.04\n",
      "______________________\n",
      "UP, RIGHT, DOWN, LEFT\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ0AAAA/CAYAAAD68sozAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAAPFJREFUeJzt3DERAjEQQNHcDXhABi0C6GmwgDqE4AEJ4OFQcO1PwXttit3iT5rMZNm2bUBpnb0A/0d05ERHTnTkREdOdORER0505ERHTnTkDrMX2HNd7+n73PdxKceN4+2Tznudn+m89fReds/KRWAM0TGB6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MgtvvSn5qYjJzpyoiMnOnKiIyc6cqIjJzpyoiMnOnKiIyc6cqIjJzpyoiMnOnKiIyc6cqIjJzpyoiMnOnKiI/cDFxgNeftd74AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAHdCAYAAAB7WRomAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAFchJREFUeJzt3LFOXde6BeCFBbUbkI5cOz3RliJ4AIuIisJ+ha3Qpku3u3RpiXgFu6BCsfwAWJFQ6I9rKxI0rpHYt4juLc6NTzQwc7Ax31f/e6651vznZA0tibXlcjkBAAAw3pP7ngAAAMBjIYABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJSsjxj0xZNX/rc9X+Tdzeu15vXSnv10+nzUVG7l+mQrqt84uBw6/jRN0+bxWfybh6zds9/+8EvUs+eLo2j8nYuXUf3oHny//Saqny0Oo/rbeOg9vurn7NV8d9RUpmnK12/0fNI9MU35vkvPgb1n21H9248XUX3qyb/+Xe3Z7377aaXeZ9P1XrUev43RPZu+z6V/iz7Xs76AAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACVry+Xyzgd98eTV3Q/Ko/Lu5vVa83o3f37zqHp2tjiM6s8XR/E19p5tR/VvP15E9ek9bB6fRfWpds+m5+yn0+fR+NcnW1H9xsFlVP90/0NUfzXfjepv07M7Fy+j+vfbb6L6x96z6TmbPq+0B0evX6pxzqb7KH2m6bmR+uPXH1f6nE2l53IqPWdTaT/dxuhzMH33SPfc585ZX8AAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAEoEMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgZP2+JwCrYO/ZdlR/Nd+N6jePz6L60TanbD6z6XD4NdI1mOZZ+UNfs/+U3s90MmYe/+vp/oeh46frcaueDa+xN+nZxGyRr0ni+mQr+0G4fKm4n47zCaU9cr44iq8RCW9hdE+0xXt2P+uRdPyrebYn0p5dxTMnfUazRVa/cXoZ1X+OL2AAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUrC2Xyzsf9MWTV3c/KI/Ku5vXa83r6Vm+lJ7lodGzPDR6lofmcz3rCxgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUrC2Xy/ueAwAAwKPgCxgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAULI+YtBvf/hlmdRvHFxG47/ffhPVzxaHUX3qfHEU1Y+ezzRN0+bxWVT/6fR5VH99shXVp/749ce1oRf4Dzd/fhP17N6z7Wj89Pk+3f8wdPx0D+1cvIzqb2N0T6XnTDqfr61nr+a7Uf3o55tKz8Bpyu85lT6j9BxIvbt5Xe3Z9N0gla75qvV4Ov405T3y9uNFfI1E+n6Trlm7Z188eRX1bPp8R5/Lo61iz6bvK6P36e/f//y3PesLGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJSsjxh08/gsqv908Dyq37l4GdWnNg4uo/q9Z9vZBeZZ+TTlc5qOs/L322+i+p0pW4Prk62ovi1dw0+nWc8+3f8Q1afS9Uvv93qer196DkxT9ozefryI6uN9Gs5n+jUc/gvF5+BpVn6+fZT9IJSeIaP30DTd4m9XeA6kRo//tUmf18YU/l0NnS+yPXSbd5u8R7Jzc7Y4jOpXbQ99qfTvTLqG6d/W/O/qYOG75jRN09V8N6qfLbL6eN+Ff4vuii9gAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAULJ+3xOYpml6uv8hqr+a70b1m8dn2fhTNv7VfCuqv430GaVmi8Oo/nxxFNXvTC+j+ra3Hy+i+tki65FpGrt+o6V7aJryfZr21GifTp/f9xT+q9Hn5t7+9tDxc6u3h65PsrM/7fG9Z9karHrPpuJz5zgrH92z6R56Wujx2Tz7W59Kn+nGdDloJncjfTdKxe+ng99/83eh/PmMvufRa7ZxcDc96wsYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJWvL5fLOB33x5NXdD8qj8u7m9VrzenqWL9Xu2e9++ynq2af7H0ZNhQfKOctDo2d5aD7Xs76AAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQMnacrm87zkAAAA8Cr6AAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAl6yMGffHk1TKpf/vxIhp/79l2VD96/E+nz6P623i6/2Ho+Ffz3aHjbx6fRfXvbl6vDZrK37r585uoZ0f34M7Fy6g+lfZTOv9pGr+PVm1P/PHrj9We/e63n6KeHW3V1uM2Ng4uo/rrk62oPj0H0z2Rzqfds6PP2dE9kvbH6D0xTfnZPFscDprJX0b3+O/f/1zt2fR9Nr2f99tvovr03WD0GXWbPXe+OIrqR79LpM8oPQc+17O+gAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAl6yMGvZrvRvU7F8+j+vcf30T1s8VhVD/Ns/LpJKy/hU+nWf31ydaYidzSp9NsjdtG98hske2JzeOzqD7dc9P0IaqOn880TZtTdg+p9J43Di6z+imrX3Xvt8eem1fzsWdOun63sWrnZjqfxjP6EnvPtqP6tx8vwitk9TsXL6P6vD+yczY/x6cpvedU2lNXU3guf2XnbCrtwVWTvqtM0zTtHWfnQLovzrePovrZSf5+cxd8AQMAACgRwAAAAEoEMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAICS9fuewDRN09P9D1H93rSdXWCela+i65Ot+57CV23z+Gzo+Ffz3aHjp1ZtPtM0vsfT8TcOLgfN5G6k5+ZsfjhoJn9J91Dag+n9rmKPr+Kcmt5+vIjqZ4usZ88XR1H96DOnsd7pM0o99nePtGenabV6fG8/e1/+Gs6o0XvirvgCBgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQMnacrm880FfPHl194PyqLy7eb3WvJ6e5Uu1e/a7336Kevbp/odRU+GBcs7y0OhZHprP9awvYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFCytlwu73sOAAAAj4IvYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQsj5i0BdPXi2T+qv5bjT+5vFZVJ9K53O+OIrqZ4vDqH6apmnj4DL+zUhP9z9E9ekz/ePXH9eiH3yhmz+/iXo2XcN0/UY/33QPfTp9HtVP0zS9334T1e89247qR+/TnYuXUf3v3/+80j072m3OtYdu1fZ12uNP/vXvle7ZdA9en2xF9an03EzX7zZWbU6j38/e3byu9ux3v/0U9Wzag433x0Tj3SB9Ruk5O/ocSOfzuXcDX8AAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAEoEMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAkvX7nsBtfDp9HtU/3f8Q1W8en0X1s+kwqr+N9B7SZ5S6mu9G9RsHl4Nmcjf2nm1H9ZtT1iOfDrL1SJ9vKl6/KV+/2SLbFxun4TVOsvKdi5fZD1Zc2rPpmqfn4DTPytMz4fpkK7vAChq9r9Me//37QRP5jPRMSMU9G3r78SKqny3Grvc0je+pdJ+mf+tWXXrupD24d5yd4+k5m2q8G6TP6Goa2+Pni6Oo/q7eJXwBAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAEoEMAAAgJL1+57AbVyfbEX1V/Os/nxxFNXPFrtR/W1czcNrnIyZB39J1+N8O+ypk8OofvP4LKpP55/uudsYfY10/I2Dy0EzuRvpGo7ukVSjp0b7Gu6haXQPju7Zxt/6VTO6x1f9nE2N7sFU/j6bvXvcpj/Sd/LR0nu+q571BQwAAKBEAAMAACgRwAAAAEoEMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAICSteVyeeeDvnjy6u4H5VF5d/N6rXk9PcuX0rM8NHqWh6bdszd/fhP17N6z7VFT4YH6XM/6AgYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAla8vl8r7nAAAA8Cj4AgYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlKyPGPTFk1fLpP7tx4to/NniMKpfNRsHl/Fvnu5/iOrTZ5pK1yC959+//3kt+sEXuvnzm6hn955tR+N/On0e1V+fbEX1o50vjuLfpM/oar4bX2OV/PHrjyvds6P3bHpGjV7v25yz6b7bPD6Lr5FIn9Gqn7Oj3w12Ll5G9el6p8931c7xaRp/D7fZd4l2z377wy9Rz6bSv62j/66mZ9ptzvHGNRL31bO+gAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAl6yMGvZrvRvWzRVaf2jw+i+rT+aee7n+If7Nqz3Tj4HLo+F+b65Ot+57CF5ktDvMfze9+Hl/ia+vZW61JIO3Zq/lq9Xhjz306fR7VP/RzoC3t8fPFUTb+STb+++03Uf3O9DKqb/TH6Guk439t53L6vjmbwnN88N/V0e+/05Sfm9PJmHncN1/AAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAEoEMAAAgBIBDAAAoGR9xKCbx2dR/dV8N6o/XxxF9XvH21H9aOn9rqLrk62ofuPgctBM7sbes6xHvoY1fGy+tp4dfc7yz9KeeuxG9+Bscfigx+fhc87+s1U7N+/r3cAXMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAErWlsvlnQ/64smrux+UR+Xdzeu15vX0LF9Kz/LQ6FkeGj3LQ/O5nvUFDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAErWlsvlfc8BAADgUfAFDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAEoEMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAIASAQwAAKBEAAMAACgRwAAAAEoEMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABK1kcM+uLJq2VS//bjRTT+bHEY1W8cXEb177ffRPWpvWfb8W+u5rtR/fniKKpPn2kqXYPfv/95bdBU/pae/e/07D/Ts3r2n+jZ1erZVLreKT37z9o9+91vP0U9e32yNWoqt6Jn795d9awvYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAEDJ+ohBr+a7Uf3OxfMR0/g/1ydbUf3s5HDQTP6ycXqZ/+gkK58tBt/DwS3uYYW9/XgR1Y9+vmnP7kwvB83kL+8/vol/M1uk58DYe/jarFrPPt3/ENXP5mPnc/7xKP6NnuW/Gb2HpvnY4aepcA+P3Obx2dDxP51m78vpeo+e/22k9/BQ3k99AQMAACgRwAAAAEoEMAAAgBIBDAAAoEQAAwAAKBHAAAAASgQwAACAEgEMAACgRAADAAAoEcAAAABKBDAAAICSteVyeeeDfvvDL3c/KA/axsFlVP/79z+vDZrK39Kz/Cc9y0OjZ3lo9CwPzV31rC9gAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlKyPGHTz+GzEsDxkx2H9zZBZfJae5f/Rszw0epaHRs/y0NxRz/oCBgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACVry+XyvucAAADwKPgCBgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACUCGAAAQIkABgAAUCKAAQAAlAhgAAAAJQIYAABAiQAGAABQIoABAACUCGAAAAAlAhgAAECJAAYAAFAigAEAAJQIYAAAACX/Axi3tfqtGZbUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = grid_world_v1()\n",
    "agent.reset()\n",
    "episodes = 1000\n",
    "steps = 500\n",
    "policies = run_training(env,agent,episodes,steps)\n",
    "num_policies = len(policies)\n",
    "indexes = list(np.linspace(0,num_policies-1,30).astype(int))\n",
    "policies2plot = []\n",
    "for i in indexes:\n",
    "    policies2plot.append(policies[i])\n",
    "plot_policies(env,policies2plot,size=(15,10))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
